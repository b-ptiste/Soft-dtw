{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw_soft import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0,5.0,3.0,6.0],requires_grad=True).unsqueeze(-1)\n",
    "y = torch.tensor([5.0,9.0,2.0],requires_grad=True).unsqueeze(-1)\n",
    "\n",
    "loss = soft_dtw(x,y)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1]) torch.Size([2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([2.0,5.0,3.0,6.0],requires_grad=True).unsqueeze(-1)\n",
    "x2 = torch.tensor([2.0,3.0,3.0,5.0],requires_grad=True).unsqueeze(-1)\n",
    "x = torch.stack([x1,x2])\n",
    "\n",
    "y1 = torch.tensor([5.0,9.0,2.0,2.0],requires_grad=True).unsqueeze(-1)\n",
    "y2 = torch.tensor([2.0,3.0,3.0,2.0],requires_grad=True).unsqueeze(-1)\n",
    "y = torch.stack([y1,y2])\n",
    "\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "loss = torch.mean(soft_dtw_batch_same_size(x,y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.8546, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5e-09'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(0.000000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='git lfs migrate info --everything', returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# List all large files in your repository\n",
    "subprocess.run(\"git lfs migrate info --everything\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4135, -0.4927,  0.3583,  0.6765,  0.0147]),\n",
       " tensor([ 0.4135,  0.4927, -0.3583, -0.6765, -0.0147]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating two 5-length vectors\n",
    "x = torch.randn(5, requires_grad=True)\n",
    "y = torch.randn(5, requires_grad=True)\n",
    "\n",
    "# Computing L2 norm between x and y\n",
    "l2_norm = torch.norm(x - y, p=2)\n",
    "\n",
    "# Computing the gradient\n",
    "l2_norm.backward()\n",
    "\n",
    "# Extracting gradients\n",
    "x_grad = x.grad\n",
    "y_grad = y.grad\n",
    "\n",
    "x_grad, y_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4135, -0.4927,  0.3583,  0.6765,  0.0147], grad_fn=<DivBackward0>),\n",
       " tensor([ 0.4135,  0.4927, -0.3583, -0.6765, -0.0147], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_grad_theoretical = (x - y) / l2_norm\n",
    "y_grad_theoretical = (y - x) / l2_norm\n",
    "\n",
    "x_grad_theoretical, y_grad_theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0,5.0,3.0,6.0],requires_grad=True).unsqueeze(-1)\n",
    "y = torch.tensor([5.0,9.0,2.0],requires_grad=True).unsqueeze(-1)\n",
    "\n",
    "# Retaining the gradient for non-leaf tensor\n",
    "x.retain_grad()\n",
    "y.retain_grad()\n",
    "\n",
    "loss = soft_dtw(x,y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [8.]]),\n",
       " tensor([[ 0.],\n",
       "         [ 0.],\n",
       "         [-8.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "# Extracting gradients\n",
    "x_grad = x.grad\n",
    "y_grad = y.grad\n",
    "\n",
    "x_grad, y_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = backward_recursion(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.5002e-20, 7.4977e-21],\n",
       "        [9.8696e-01, 2.6084e-02, 3.2187e-06],\n",
       "        [9.7392e-01, 1.0178e-10, 2.6084e-02],\n",
       "        [2.6193e-01, 9.7392e-01, 1.0000e+00]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x.repeat(3,1,1).shape)\n",
    "\n",
    "E = backward_recursion_batch_same_size(x.repeat(3,1,1),y.repeat(3,1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 1.5002e-20, 7.4977e-21],\n",
       "         [9.8696e-01, 2.6084e-02, 3.2187e-06],\n",
       "         [9.7392e-01, 1.0178e-10, 2.6084e-02],\n",
       "         [2.6193e-01, 9.7392e-01, 1.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 1.5002e-20, 7.4977e-21],\n",
       "         [9.8696e-01, 2.6084e-02, 3.2187e-06],\n",
       "         [9.7392e-01, 1.0178e-10, 2.6084e-02],\n",
       "         [2.6193e-01, 9.7392e-01, 1.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 1.5002e-20, 7.4977e-21],\n",
       "         [9.8696e-01, 2.6084e-02, 3.2187e-06],\n",
       "         [9.7392e-01, 1.0178e-10, 2.6084e-02],\n",
       "         [2.6193e-01, 9.7392e-01, 1.0000e+00]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back(x,y,E):\n",
    "    p = len(x[0])\n",
    "    m = len(y)\n",
    "    print(p,m)\n",
    "\n",
    "    a = (torch.matmul(torch.ones(p,m), E.transpose(0,1)))\n",
    "    a= a * x\n",
    "    b = (y.transpose(0,1) @ E.transpose(0,1))\n",
    "    return 2*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "1 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.0000,  -6.2869,  -5.8435, -15.2064],\n",
       "        [  0.0000,  -0.2087,   0.1565,  -1.7913],\n",
       "        [ -4.0000,  -4.2608,  -3.8435, -10.7347],\n",
       "        [  2.0000,   1.8174,   2.1565,   2.6803]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "\n",
    "back(x,y,E)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
